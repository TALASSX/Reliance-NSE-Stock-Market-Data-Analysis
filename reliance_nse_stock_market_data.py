# -*- coding: utf-8 -*-
"""Reliance NSE Stock Market Data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11Ik7YwQW1qfrvFwIkA6zyK-ZWtAH5HfR
"""

!pip install pyspark

"""Problem statement:
You work as a Big Data Engineer at GrapeVine Pvt. Ltd. Your company is currently working as a 
Data Analytics consultant for a hedge fund. Due to the size of the available dataset, the 
company requires you to increase computational efficiency using Apache Spark. You have been 
assigned certain tasks for the fulfillment of this analysis through stock market backtesting.

Dataset description:
The dataset used for this assignment is ‘Reliance NSE Stock Market Data.’ The relevant fields 
that will be put to use in further analysis are as follows:
time – The timestamp of the data record (separated by 5-minute intervals)
open – The opening price of the stock
high – The highest point of the stock in the last 5-minute interval
low – The lowest point of the stock in the last 5-minute interval 
close – The price of the stock at the end of the 5-minute interval
The rest of the fields or columns can be ignored
"""

from pyspark.sql import SparkSession
spark = SparkSession.builder.appName("NSE").getOrCreate()
df=spark.read.format('csv')\
.option("header","true")\
.option("inferSchema","true")\
.load("/content/NSE_RELIANCE_5_1.csv")
df.show(5)

# Create a temporary view of the DataFrame
df.createOrReplaceTempView("NSE_Data")

# Query the table and show the result
result = spark.sql("SELECT * FROM NSE_Data")
#result.unpersist()
result.show()

# Find out the average ‘close’ price of Reliance throughout the duration of the dataset
Avg_Close_Price=spark.sql("select Avg(close) as avg_close_price from NSE_Data ")
Avg_Close_Price.show()

#If a Reliance stock was bought at the beginning of the trading day, ‘2020-04-07’ (YYYY-MM-DD), 
#at the close price of the first 5-minute window, scan the dataset to find out the point to sell the 
#stock to maximize profits. You are required to print the specific timestamp
time_stamp=spark.sql("select time from NSE_DATA where time>='2020-04-07' and close=(select max(close) from NSE_Data where time>='2020-04-07')")
time_stamp.show()

#Find out the net profit or net loss to be accumulated if one stock of Reliance is bought at the 
#opening of every 5-minute slot and sold at the lowest possible point in that 5-minute slot

lowest_possible_point=spark.sql("select sum(open-low) as net_profit_loss from NSE_Data")
lowest_possible_point.show()

# Find out the net profit or net loss to be accumulated if one stock of Reliance is bought at the 
#opening of every 5-minute slot and sold at the highest possible point in that 5-minute slot
highest_possible_point=spark.sql("select sum(high-open) as net_profit_high from NSE_Data")
highest_possible_point.show()